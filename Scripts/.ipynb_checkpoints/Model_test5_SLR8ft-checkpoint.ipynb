{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario notes\n",
    "\n",
    "Using the NOAA SLR scenarios we can do a couple different iterations \n",
    "\n",
    "NOAA SLR Scenarios  https://coast.noaa.gov/slr/#/layer/sce/0/-17821114.951125123/1934329.2023005919/3/satellite/60/0.8/2090/interHigh/midAccretion\n",
    "\n",
    "Year 2040\n",
    "Intermediate Low : 0.72ft 0.22m \n",
    "Intermediate : 1.02ft\n",
    "Intermediate High : 1.38ft\n",
    "High : 1.71ft\n",
    "Extreme : 1.94ft  0.59m\n",
    "\n",
    "                    \n",
    "Year 2090               \n",
    "Intermediate Low : 1.84ft  0.56m\n",
    "Intermediate : 3.44ft\n",
    "Intermediate High : 5.15ft\n",
    "High : 6.92ft\n",
    "Extreme : 8.33ft  2.54m\n",
    "\n",
    "\n",
    "Three scenarios to model, and present ranges from:  \n",
    "\n",
    "2040\n",
    "Low : 0.72ft 0.22m  to  Extreme : 1.94ft  0.59\n",
    "\n",
    "Year 2090 No change in climate\n",
    "Low : 1.84ft  0.56m  to Extreme : 8.33ft  2.54m\n",
    "\n",
    "Year 2090 RCP4.5  climate  \n",
    "Low : 1.84ft  0.56m  to Extreme : 8.33ft  2.54m\n",
    "\n",
    "\n",
    "Thus need 6 model runs with the following levels: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Notes and limitations: \n",
    "- While the subsidence induced SLR is likely not factored into these predictions the amount of total subsidence as projected by Han is in the range of 30-40 cm, with \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container { width: 95%;} div#menubar-container { width: 85%; } div#maintoolbar-container { width: 99%; } </style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.2 | packaged by conda-forge | (default, Feb 28 2020, 16:38:51) [MSC v.1916 64 bit (AMD64)]\n",
      "numpy version: 1.18.1\n",
      "matplotlib version: 3.1.3\n",
      "flopy version: 3.3.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container { width: 95%;} div#menubar-container { width: 85%; } div#maintoolbar-container { width: 99%; } </style> \"\"\"))\n",
    " \n",
    "# %matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import flopy\n",
    "import flopy.utils.binaryfile as bf\n",
    "from flopy.export.shapefile_utils import shp2recarray\n",
    "from rasterio import Affine\n",
    "from flopy.utils.reference import SpatialReference\n",
    "from flopy.utils.postprocessing import get_transmissivities, get_water_table, get_gradients\n",
    "\n",
    "import shapefile    # not used directly here but for some reason flopy needs this to do shapefile stuff and BTW its not import pyshp as you would think its import shapefile, dumb...\n",
    "import pandas as pd\n",
    "import fiona\n",
    "from rasterio.features import rasterize\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import geopandas\n",
    "from osgeo import gdal\n",
    "\n",
    "#import simplekml\n",
    "import ogr\n",
    "from shapely.wkb import loads\n",
    "\n",
    "from scipy.interpolate import interp2d\n",
    "import scipy.optimize as opt\n",
    "\n",
    "\n",
    "print(sys.version)\n",
    "print('numpy version: {}'.format(np.__version__))\n",
    "print('matplotlib version: {}'.format(mpl.__version__))\n",
    "print('flopy version: {}'.format(flopy.__version__))\n",
    "\n",
    "#Set name of MODFLOW exe\n",
    "#  assumes executable is in users path statement\n",
    "exe_name = 'mf2005'\n",
    "if platform.system() == 'Windows':\n",
    "    exe_name = 'mf2005.exe'\n",
    "\n",
    "workspace = os.path.join(\"..\", \"..\", 'RISA_yr6_GIT_ignored_files', 'Flo_py_wrkspace5_SLR8ft')\n",
    "#make sure workspace directory exists\n",
    "if not os.path.exists(workspace):\n",
    "    os.makedirs(workspace)\n",
    "    \n",
    "tempspace = os.path.join(workspace, \"temp\")\n",
    "#make sure workspace directory exists\n",
    "if not os.path.exists(tempspace):\n",
    "    os.makedirs(tempspace)\n",
    "    \n",
    "figurespace = os.path.join(workspace, \"Figures\")\n",
    "if not os.path.exists(figurespace):\n",
    "    os.makedirs(figurespace)\n",
    "    \n",
    "WGS84UTM2S_string = 'PROJCS[\"WGS_1984_UTM_Zone_2S\",GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-171],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",10000000],UNIT[\"Meter\",1]]'\n",
    "pd.set_option('display.max_rows', 75)\n",
    "\n",
    "# define the spatial reference object \n",
    "model_epsg = 32702   # epsg code specifying coordinate reference system: in this case, UTM zone 2S, WGS 84, A proj4 string has also been fetched from <spatialreference.org> using the supplied epsg code.\n",
    "\n",
    "# in line plotting and saving options. Change these to plot or not to plot inline\n",
    "Plotnsave_plot = True\n",
    "Plotnsave_save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model geometry notes\n",
    "\n",
    "\n",
    "model boundaries square at \n",
    "X\tY\n",
    "- 530200\t8425825\n",
    "- 537700\t8425825\n",
    "- 537700\t8418325\n",
    "- 530200\t8418325\n",
    "\n",
    "with length of 7500 m on both sides\n",
    "\n",
    "\n",
    "next steps \n",
    "- try and just follow existing github model notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile Boundaries: (530200.0, 8418325.0, 537700.0000000009, 8425825.000000002)\n",
      "wrote ..\\..\\RISA_yr6_GIT_ignored_files\\Flo_py_wrkspace5_SLR8ft\\Model_polyarea.shp\n"
     ]
    }
   ],
   "source": [
    "''' Define the number of layers, rows and columns.'''\n",
    "# Note works at 100, 150, 300, 750, 1500\n",
    "# Does not work at 600\n",
    "\n",
    "ncol = 1500\n",
    "nrow = 1500\n",
    "nlay = 1\n",
    "\n",
    "# model run times\n",
    "nper = 1                     # Number of model stress periods (the default is 1)\n",
    "perlen = [3650]              # An array of the stress period lengths in days separated by commas\n",
    "nstp = [1]      # Number of time steps in each stress period (default is 1).\n",
    "save_head = [3650]\n",
    "steady = True\n",
    "rotation = 0                             # rotation (positive counterclockwise)\n",
    "\n",
    "# this cell inports the boundary shapefile to make the model around\n",
    "ra = shp2recarray(os.path.join(\"..\", \"Data/Raw/GIS\", 'model_square.shp'))\n",
    "# these are the bondaries of the shapefile\n",
    "shp_xmin = round(ra.geometry[0].bounds[0],1)\n",
    "shp_ymin = round(ra.geometry[0].bounds[1],1)\n",
    "shp_xmax = round(ra.geometry[0].bounds[2],1)\n",
    "shp_ymax = round(ra.geometry[0].bounds[3],1)\n",
    "print(\"Shapefile Boundaries: {}\".format(ra.geometry[0].bounds))  \n",
    "\n",
    "xll = int(shp_xmin)  # Lower left corner of model grid  \n",
    "yll = int(shp_ymin)   # Lower left corner of model grid \n",
    "\n",
    "\n",
    "# grid spacing as a percentage of model x domain (in model units) note 10% buffer around boundary\n",
    "delr = abs(int((shp_xmax-shp_xmin)/ncol))   # the width of each cell\n",
    "delc = abs(int((shp_ymax-shp_ymin)/nrow))   # the height of eech cell\n",
    "delr_4_sr  = np.ones(ncol, dtype=float) * delr    # This just puts the above into an array for the sr object \n",
    "delc_4_sr = np.ones(nrow, dtype=float) * delc   \n",
    "\n",
    "# create the model boundary area polygon\n",
    "sr = SpatialReference(delr=[delr_4_sr.sum()], delc=[delc_4_sr.sum()], xll=xll, yll=yll, rotation=rotation, proj4_str=WGS84UTM2S_string, lenuni=2) #  # model length units (1 for feet, 2 for meters (default)) (also calculeted uper left corner of model) \n",
    "sr.write_shapefile(os.path.join(workspace, 'Model_polyarea.shp'))          # write a shapefile of the model area for later use\n",
    "prj = open(os.path.join(workspace, 'Model_polyarea.prj'), \"w\"); prj.write(WGS84UTM2S_string) ; prj.close()     # write the .prj file manually\n",
    "#print(\"corners are at {}\".format(sr.get_extent()))\n",
    "\n",
    "# create the model boundary grid polygon   (NOTE THIS MUST OVERWRITE THe PREVIOUS sr. definition!)\n",
    "sr = SpatialReference(delr=delr_4_sr, delc=delc_4_sr, xll=xll, yll=yll, rotation=rotation, proj4_str= '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs' , lenuni=2) #  # model length units (1 for feet, 2 for meters (default)) (also calculeted uper left corner of model) \n",
    "sr.write_shapefile(os.path.join(workspace, 'Model_grid.shp'))          # write a shapefile of the model grid for later use\n",
    "prj = open(os.path.join(workspace, 'Model_grid.prj'), \"w\"); prj.write(WGS84UTM2S_string) ; prj.close()   # write the .prj file manually\n",
    "\n",
    "# output control parameters\n",
    "spd = {(0, 0): ['print head', 'print budget', 'save head', 'save budget']}    \n",
    "\n",
    "if Plotnsave_plot: \n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    Tutuila = geopandas.read_file(os.path.join(\"..\", \"Data/Raw/GIS\", 'model_square.shp'))\n",
    "    Grid = geopandas.read_file(os.path.join(workspace, 'Model_grid.shp'))\n",
    "    Grid.plot(ax=ax, facecolor=\"white\", edgecolor=\"Black\", linewidth=.2)\n",
    "    Tutuila.plot(ax=ax, linewidth=2, alpha = .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Layer elevations from a DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set model top to DEM\n",
    "# Needed to clip the raster to appropriate dimensions, () https://rasterio.readthedocs.io/en/stable/topics/masking-by-shapefile.html)\n",
    "Raster_2_Clip = os.path.join(\"..\",  'Data/Raw/GIS/3m_DEM', '3m_dem_cp.tif')\n",
    "Clipped_raster = os.path.join(workspace, \"DEM_10m_clip.asc\")\n",
    "\n",
    "with fiona.open(os.path.join(workspace, 'Model_polyarea.shp'), \"r\") as shapefile:\n",
    "    features = [feature[\"geometry\"] for feature in shapefile]\n",
    "    \n",
    "with rasterio.open(Raster_2_Clip) as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, features,\n",
    "                                                        crop=True)\n",
    "out_meta = src.meta.copy()\n",
    "\n",
    "out_meta.update({\"driver\": \"AAIGrid\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "with rasterio.open(Clipped_raster, \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "    \n",
    "# Now disect the clipped .asc into a \n",
    "Top_raw = np.loadtxt(Clipped_raster, skiprows=7)   # the 7th row was a no data row for some reason not sure why, if another DEM is used might need to skiprows back to 6\n",
    "\n",
    "y = np.linspace(0, np.shape(Top_raw)[0]-1, np.shape(Top_raw)[0])   \n",
    "x = np.linspace(0, np.shape(Top_raw)[1]-1, np.shape(Top_raw)[1])\n",
    "\n",
    "y2 = np.linspace(0, np.shape(y)[0], nrow)   # this defines the number of cells to resample to on the y direction, first number is the original height of the SWB2 recharge map, second number is going to be new height in # of cells\n",
    "x2 = np.linspace(0, np.shape(x)[0], ncol)   # this defines the number of cells to resample to on the x direction, first number is the original width of the SWB2 recharge map, second number is going to be new width in # of cells\n",
    "\n",
    "f = interp2d(x, y, Top_raw, kind='cubic')\n",
    "top = f(x2, y2)\n",
    "\n",
    "botm = -500    # this will clearly need to change to accomadate the Tutuila bathymetry\n",
    "top = np.where(top <= botm, botm+10, top) # force top elevations to always be higher than bottom elevations\n",
    "\n",
    "if Plotnsave_plot: \n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "    qm = sr.plot_array(top, ax=ax)\n",
    "    ax.set_aspect(1); plt.colorbar(qm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting heads will be tricky.  Easiest might be to assign starting heads of 0.01 in ocean, then heads of 10 m less than top elevation in land surface areas, if optimization yields different starting heads then can modify. could also use the ending heads from the regional model. \n",
    "\n",
    "\n",
    "overall, I bound needs to be "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### starting heads\n",
    "##### - Note need to change the land ocean if changing the coastline position \n",
    "##### - also need to change the Ocean_starting_head to whatever the scenario is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ocean_starting_head = 2.54   # in meters \n",
    "\n",
    "\n",
    "\n",
    "## First import regional heads from the regional model\n",
    "\n",
    "Raster_2_Clip = os.path.join(\"..\",  'Data/Raw/From_regional', 'PyPCGA_model_Heads_Clip.tif')\n",
    "Clipped_raster = os.path.join(workspace, \"PyPCGA_model_Heads_Clip.asc\")\n",
    "\n",
    "with fiona.open(os.path.join(workspace, 'Model_polyarea.shp'), \"r\") as shapefile:\n",
    "    features = [feature[\"geometry\"] for feature in shapefile]\n",
    "    \n",
    "with rasterio.open(Raster_2_Clip) as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, features,\n",
    "                                                        crop=True)\n",
    "out_meta = src.meta.copy()\n",
    "\n",
    "out_meta.update({\"driver\": \"AAIGrid\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "with rasterio.open(Clipped_raster, \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "    \n",
    "# Now disect the clipped .asc into a \n",
    "Top_raw = np.loadtxt(Clipped_raster, skiprows=7)   # the 7th row was a no data row for some reason not sure why, if another DEM is used might need to skiprows back to 6\n",
    "\n",
    "y = np.linspace(0, np.shape(Top_raw)[0]-1, np.shape(Top_raw)[0])   \n",
    "x = np.linspace(0, np.shape(Top_raw)[1]-1, np.shape(Top_raw)[1])\n",
    "\n",
    "y2 = np.linspace(0, np.shape(y)[0], nrow)   # this defines the number of cells to resample to on the y direction, first number is the original height of the SWB2 recharge map, second number is going to be new height in # of cells\n",
    "x2 = np.linspace(0, np.shape(x)[0], ncol)   # this defines the number of cells to resample to on the x direction, first number is the original width of the SWB2 recharge map, second number is going to be new width in # of cells\n",
    "\n",
    "f = interp2d(x, y, Top_raw, kind='cubic')\n",
    "regional_Heads = f(x2, y2)\n",
    "\n",
    "#botm = -500    # this will clearly need to change to accomadate the Tutuila bathymetry\n",
    "#top = np.where(top <= botm, botm+10, top) # force top elevations to always be higher than bottom elevations\n",
    "\n",
    "\n",
    "# then explicitly say that the ocean area has a specified head, since the regional heads are fuzzy\n",
    "\n",
    "with fiona.open(os.path.join(\"..\",  'Data/Raw/GIS/ibounds/For_heads', 'Land_Ocean_SLR8ft.shp')) as src:   #    read in Tutuila shapefile\n",
    "    records = [r for r in src] \n",
    "geoms = [r['geometry'] for r in records]       # shapefile shape\n",
    "attr = [r['properties'] for r in records]      # shapefile attributes\n",
    "geoms = [(g, attr[i]['OceanCell'])for i, g in enumerate(geoms) ]              # select the attribute to map onto the raster grid\n",
    "# affine: work with the geometry to change from raster to grid reference frame \n",
    "trans = Affine(delr, rotation, sr.xul, sr.rotation, -delc, sr.yul)\n",
    "mask = rasterize(geoms, out_shape=(nrow, ncol), transform=trans) # the actual rasterization \n",
    "\n",
    "masked_heads = abs(regional_Heads)*mask                        # set ocean cells to a negative number through multoplication with -1\n",
    "start_heads = np.where(masked_heads < 0, Ocean_starting_head, masked_heads) # Set ocean cells (defined as any negative values in the array) to Ocean_starting_head value\n",
    "\n",
    "if Plotnsave_plot: \n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "    qm = sr.plot_array(start_heads, ax=ax)\n",
    "    ax.set_aspect(1); plt.colorbar(qm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make new ibound and specified head \n",
    "\n",
    "\n",
    "##### - Note need to change theibound_specHd_w_100m_buff_SLR8ftif changing the coastline position \n",
    "\n",
    "\n",
    "- Negative ibound (-1) is constant head\n",
    "- Ibound of (0) is inactive\n",
    "- Any positive Ibound (1) is variable head (active) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use a Tutuila polygon to define the model active area as the island \n",
    "\n",
    "with fiona.open(os.path.join(\"..\", 'Data/Raw/GIS/ibounds', 'ibound_specHd_w_100m_buff_SLR8ft.shp')) as src:   #    read in Tutuila shapefile\n",
    "    records = [r for r in src] \n",
    "geoms = [r['geometry'] for r in records]       # shapefile shape\n",
    "attr = [r['properties'] for r in records]      # shapefile attributes\n",
    "geoms = [(g, attr[i]['ibound'])for i, g in enumerate(geoms) ]              # select the attribute to map onto the raster grid\n",
    "# affine: work with the geometry to change from raster to grid reference frame \n",
    "trans = Affine(delr, rotation, sr.xul, sr.rotation, -delc, sr.yul)\n",
    "ibound = rasterize(geoms, out_shape=(nrow, ncol), transform=trans) # the actual rasterization \n",
    "\n",
    "if Plotnsave_plot: \n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "    qm = sr.plot_array(ibound, ax=ax)\n",
    "    ax.set_aspect(1); plt.colorbar(qm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Drains \n",
    "this takes a minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conductance_value = 3500\n",
    "\n",
    "# Intersect streams with the grid cells using GEOPANDAS!! :)\n",
    "lines = geopandas.GeoDataFrame.from_file(os.path.join(\"..\", \"Data/Raw/GIS\", \"Streams\", 'Streams_All_WGS2S.shp'))\n",
    "poly = geopandas.GeoDataFrame.from_file(os.path.join(workspace, 'Model_grid.shp'))\n",
    "# Do the spatial intersect to just pull out cells that hit streams\n",
    "intersections= geopandas.sjoin(poly, lines, how=\"inner\", op='intersects')\n",
    "intersections[\"x\"] = intersections.centroid.x # pull out the x coordiate\n",
    "intersections[\"y\"] = intersections.centroid.y # pull out the y coordiate\n",
    "intersections[\"Cond\"] = conductance_value\n",
    "# Write the geopandas dataframe to a esri shapefile \n",
    "intersections.to_file(driver = 'ESRI Shapefile', filename = os.path.join(workspace, 'Stream_grid_intersects.shp'))          # write a shapefile of the model grid for later use\n",
    "prj = open(os.path.join(workspace, 'Stream_grid_intersects.prj'), \"w\"); prj.write(WGS84UTM2S_string) ; prj.close()   # write the .prj file manually\n",
    "\n",
    "# Extract elevation values to the points from the DEM\n",
    "Clipped_DEM_raster = os.path.join(workspace, \"DEM_10m_clip.asc\")   # from the DEM used above\n",
    "src = rasterio.open(Clipped_DEM_raster) \n",
    "coords = [(x,y) for x, y in zip(intersections[\"x\"], intersections[\"y\"])]  # This woll pull the cooordinate values out of the centrods of the intersections frame above\n",
    "intersections['RastVal'] = [x[0] for x in src.sample(coords)]\n",
    "\n",
    "\n",
    "# Modify elevations a bit\n",
    "intersections['RastVal'][intersections['RastVal'] > 100] = intersections['RastVal'] - 50\n",
    "intersections['RastVal'][intersections['RastVal'] > 10] = intersections['RastVal'] - 1\n",
    "intersections['RastVal'][intersections['RastVal'] > 3] = intersections['RastVal'] - 1\n",
    "intersections['RastVal'][intersections['RastVal'] > 2] = intersections['RastVal'] - 1\n",
    "intersections['RastVal'][intersections['RastVal'] > 1] = intersections['RastVal'] - .5\n",
    "\n",
    "# Reset any values that ended up as 0s\n",
    "intersections['RastVal'][intersections['RastVal'] <= Ocean_starting_head] = Ocean_starting_head  #(will make pink box)\n",
    "\n",
    "# Write to shapefile \n",
    "intersections.to_file(driver = 'ESRI Shapefile', filename = os.path.join(workspace, 'Stream_grid_intersects_Elevations.shp'))          # write a shapefile of the model grid for later use\n",
    "prj = open(os.path.join(workspace, 'Stream_grid_intersects_Elevations.prj'), \"w\"); prj.write(WGS84UTM2S_string) ; prj.close()   # write the .prj file manually\n",
    "\n",
    "\n",
    "# Create a model square array with the point values elevation as the elevation \n",
    "with fiona.open(os.path.join(workspace, 'Stream_grid_intersects_Elevations.shp')) as src:   #    read in Tutuila shapefile\n",
    "    records = [r for r in src] \n",
    "geoms = [r['geometry'] for r in records]       # shapefile shape\n",
    "attr = [r['properties'] for r in records]      # shapefile attributes\n",
    "geoms = [(g, attr[i]['RastVal'])for i, g in enumerate(geoms) ]              # select the attribute to map onto the raster grid\n",
    "# affine: work with the geometry to change from raster to grid reference frame \n",
    "trans = Affine(delr, rotation, sr.xul, sr.rotation, -delc, sr.yul)\n",
    "Stream_elev = rasterize(geoms, out_shape=(nrow, ncol), transform=trans) # the actual rasterization \n",
    "\n",
    "if Plotnsave_plot: \n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "    qm = sr.plot_array(Stream_elev, ax=ax)\n",
    "    ax.set_aspect(1); plt.colorbar(qm)\n",
    "\n",
    "# Create a model square array with the point values conductance defined as whatever.\n",
    "with fiona.open(os.path.join(workspace, 'Stream_grid_intersects_Elevations.shp')) as src:   #    read in Tutuila shapefile\n",
    "    records = [r for r in src] \n",
    "geoms = [r['geometry'] for r in records]       # shapefile shape\n",
    "attr = [r['properties'] for r in records]      # shapefile attributes\n",
    "geoms = [(g, attr[i]['Cond'])for i, g in enumerate(geoms) ]              # select the attribute to map onto the raster grid\n",
    "# affine: work with the geometry to change from raster to grid reference frame \n",
    "trans = Affine(delr, rotation, sr.xul, sr.rotation, -delc, sr.yul)\n",
    "Stream_conductance = rasterize(geoms, out_shape=(nrow, ncol), transform=trans) # the actual rasterization \n",
    "\n",
    "if Plotnsave_plot: \n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "    qm = sr.plot_array(Stream_conductance, ax=ax)\n",
    "    ax.set_aspect(1); plt.colorbar(qm)\n",
    "\n",
    "\n",
    "# Save in Flopy friendly format\n",
    "drnElv_lst = pd.DataFrame({\n",
    "                 'lay':  0,\n",
    "                 'row':  np.nonzero(Stream_elev)[0], # + 1,\n",
    "                 'col':  np.nonzero(Stream_elev)[1], # + 1,\n",
    "                 'elv':  Stream_elev[np.nonzero(Stream_elev)],\n",
    "                 'cond': Stream_conductance[np.nonzero(Stream_conductance)]}, \n",
    "             columns=['lay', 'row', 'col', 'elv', 'cond'])\n",
    "\n",
    "# Convert the DataFrame into a list of lists for the drn constructor\n",
    "stress_period_data = drnElv_lst.values.tolist()\n",
    "\n",
    "# Create a dictionary, 1 entry for each of the stress periods.\n",
    "stress_period_data_drain = {0: stress_period_data}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pumping wells \n",
    "Using ASPA data and the average pumprates 2005-2017 based only last wells pumprate master sheet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pump_wells = pd.read_csv(os.path.join(\"..\",  'Data/Raw/GIS/Pump_wells', 'ASPA_wells_clip_UTM2s.csv'))\n",
    "\n",
    "Pump_wells['col_num'] = Pump_wells['x_utm'].apply(lambda x_utm_val: math.ceil((x_utm_val-xll)/delr) )          # this formula calculates the column number based on the x coordinate   Not sure why rows and cols are opposite what you think but they are\n",
    "Pump_wells['row_num'] = Pump_wells['y_utm'].apply(lambda y_utm_val: (1+nrow)-math.ceil((y_utm_val-yll)/delc) )   # this formula calculates the row number based on the y coordinate \n",
    "Pump_wells['rowcol']  = list(zip(Pump_wells.row_num, Pump_wells.col_num)) \n",
    "\n",
    "# This takes obs wells that occupy the same cell and averages them! \n",
    "Unique_PumpWells = Pump_wells.groupby('rowcol', as_index=False).sum()                                               # Average the duplicate WLs that fall into a single cell, to get one \"observed\" water level for that cell \n",
    "\n",
    "# make new unique names for each obs point\n",
    "Unique_PumpWells[\"name\"] = \"PumpWellCell_\"+Unique_PumpWells.index.map(str)\n",
    "\n",
    "# set layer values \n",
    "Unique_PumpWells[\"Layer\"] = 0\n",
    "\n",
    "# Convert GPM to m3/d\n",
    "Unique_PumpWells[\"m3pd\"] = Unique_PumpWells[\"PumpGMP\"]*-5.45099\n",
    "\n",
    "SP_frame = Unique_PumpWells[['Layer', 'row_num', 'col_num', 'm3pd']]\n",
    "\n",
    "stress_period_data = SP_frame.values.tolist()\n",
    "# Create a dictionary, 1 entry for each of the stress periods.\n",
    "stress_period_data_PmpWells = {0: stress_period_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation points\n",
    "\n",
    "note need to cut out obs that are not within the model domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pdevel_WLs = pd.read_csv(os.path.join(\"..\",  'Data/Raw/Water_levels', 'Predevelop_WLs_MOD_vai183.csv'))\n",
    "\n",
    "# Cut out observations that are outside of the model square (dont need the y's but could add those too for shoots and giggls\n",
    "Pdevel_WLs = Pdevel_WLs[Pdevel_WLs['x_utm'] > shp_xmin]\n",
    "Pdevel_WLs = Pdevel_WLs[Pdevel_WLs['x_utm'] < shp_xmax]\n",
    "\n",
    "Pdevel_WLs['col_num'] = Pdevel_WLs['x_utm'].apply(lambda x_utm_val: math.ceil((x_utm_val-xll)/delr) )          # this formula calculates the column number based on the x coordinate   Not sure why rows and cols are opposite what you think but they are\n",
    "Pdevel_WLs['row_num'] = Pdevel_WLs['y_utm'].apply(lambda y_utm_val: (1+nrow)-math.ceil((y_utm_val-yll)/delc) )   # this formula calculates the row number based on the y coordinate \n",
    "Pdevel_WLs['rowcol']  = list(zip(Pdevel_WLs.row_num, Pdevel_WLs.col_num))                                      # just make a tuplel of the row and col\n",
    "\n",
    "# This takes obs wells that occupy the same cell and averages them! \n",
    "Unique_WLs = Pdevel_WLs.groupby('rowcol', as_index=False).mean()                                               # Average the duplicate WLs that fall into a single cell, to get one \"observed\" water level for that cell \n",
    "\n",
    "# make new unique names for each obs point\n",
    "Unique_WLs[\"name\"] = \"Obs_\"+Unique_WLs.index.map(str)\n",
    "\n",
    "nobs = len(Unique_WLs['WL_m_MSL']) \n",
    "layervals = [0] * nobs\n",
    "rowvals = list(Unique_WLs['row_num'].astype(int))\n",
    "colvals = list(Unique_WLs['col_num'].astype(int))\n",
    "obsvals = list(Unique_WLs['WL_m_MSL'])\n",
    "obsnames = list(Unique_WLs[\"name\"])\n",
    "\n",
    "if Plotnsave_plot: \n",
    "    gdf = geopandas.GeoDataFrame(Unique_WLs, geometry=geopandas.points_from_xy(Unique_WLs.x_utm, Unique_WLs.y_utm))\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "    Grid.plot(ax=ax, facecolor=\"white\", edgecolor=\"Black\", linewidth=.2, alpha = .2)\n",
    "    qm = sr.plot_array(ibound, ax=ax, alpha = .2)\n",
    "    ax.set_aspect(1); plt.colorbar(qm)\n",
    "    gdf.plot(ax=ax, color='black', markersize=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Recharge .asc from SWB output into MODFLOW rech array\n",
    "(note I am not sure what happens when the model area is bigger then the raster....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWB_output_recharge = os.path.join(\"..\",  'Data/Raw/GIS/Recharge','Normalized_RCP4p5_Net_Infil.asc')    # Normalized_RCP4p5_Net_Infil    net_infiltration_annual_Base\n",
    "\n",
    "\n",
    "# Needed to clip the raster to appropriate dimensions, () https://rasterio.readthedocs.io/en/stable/topics/masking-by-shapefile.html)   \n",
    "Raster_2_Clip = os.path.join(SWB_output_recharge)\n",
    "Clipped_raster = os.path.join(workspace, \"raw_net_infiltration_clip.asc\")\n",
    "\n",
    "with fiona.open(os.path.join(workspace, 'Model_polyarea.shp'), \"r\") as shapefile:\n",
    "    features = [feature[\"geometry\"] for feature in shapefile]\n",
    "    \n",
    "with rasterio.open(Raster_2_Clip) as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, features, crop=True)\n",
    "    \n",
    "out_meta = src.meta.copy()\n",
    "out_meta.update({\"driver\": \"AAIGrid\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "\n",
    "with rasterio.open(Clipped_raster, \"w\", **out_meta) as dest:          # create the new clipped .asc file\n",
    "    dest.write(out_image)\n",
    "    \n",
    "# Now disect the clipped .asc into a \n",
    "recharge_raw_SWB = np.loadtxt(Clipped_raster, skiprows=6)\n",
    "\n",
    "y = np.linspace(0, np.shape(recharge_raw_SWB)[0]-1, np.shape(recharge_raw_SWB)[0])   \n",
    "x = np.linspace(0, np.shape(recharge_raw_SWB)[1]-1, np.shape(recharge_raw_SWB)[1])\n",
    "\n",
    "y2 = np.linspace(0, np.shape(y)[0], nrow)   # this defines the number of cells to resample to on the y direction, first number is the original height of the SWB2 recharge map, second number is going to be new height in # of cells\n",
    "x2 = np.linspace(0, np.shape(x)[0], ncol)   # this defines the number of cells to resample to on the x direction, first number is the original width of the SWB2 recharge map, second number is going to be new width in # of cells\n",
    "\n",
    "f = interp2d(x, y, recharge_raw_SWB, kind='cubic')\n",
    "recharge_resampled = f(x2, y2)\n",
    "recharge_converted =  recharge_resampled* (0.0254/365)   # recharge comes out of SWB in inches/year and needs to be converted to m/day\n",
    "\n",
    "recharge_converted = np.where(recharge_converted < 0, 0.001, recharge_converted)   # Interpolation made some negative values, fix that issue by setting them to a positive value\n",
    "\n",
    "rch_data = {0: recharge_converted}   # dictionary form to specify that it is only on first layer\n",
    "\n",
    "if Plotnsave_plot: \n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "    qm = sr.plot_array(recharge_converted, ax=ax)\n",
    "    ax.set_aspect(1); plt.colorbar(qm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydraulic condictivty assigned based on zones as defined by shapefiles in a folder\n",
    "\n",
    "The values at the top of this cell can be modified to change the conductivity in each zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rasterize the HK zones: \n",
    "def rastah_zone(shp):\n",
    "    with fiona.open(shp) as src:   #    read in Tutuila shapefile\n",
    "            records = [r for r in src]   \n",
    "    geoms = [r['geometry'] for r in records]       # shapefile shape\n",
    "    attr = [r['properties'] for r in records]      # shapefile attributes\n",
    "    geoms = [(g, attr[i]['par_code']) for i, g in enumerate(geoms)]              # select the attribute to map onto the raster grid\n",
    "    # affine: work with the geometry to change from raster to grid reference frame \n",
    "    trans = Affine(delr, rotation, sr.xul, sr.rotation, -delc, sr.yul)\n",
    "    Outrastah = rasterize(geoms, out_shape=(nrow, ncol), transform=trans) # the actual rasterization \n",
    "    return Outrastah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the  values this cell is set up for optimization\n",
    "HK_raster = rastah_zone(os.path.join(\"..\",  'Data/Raw/GIS/Geo_units/v2', 'NPS_simplified_geo_v2.shp'))\n",
    "\n",
    "## Initial starting point before 3-4 rounds of calibration  was calgood = [ 5, 5, 5, 5, 5, 5, 0.2, .2, .2, .4, 0.5, 5]\n",
    "#calgood =  [2.6, 39, 1, 14, 3.7, 1.2, 0.001, 0.37, 0.9, 0.7, 0.3, 1], [0.7, 16, 16,  0.5, 1.0, 0.5, 0.002, 0.75, 0.17, 0.3, 0.0018, 3.75]  calgood = [1.3, 27, 11.5, 0.3, 1.2, 0.27, 0.00158, 0.73, 0.42, 0.38, 0.003 , 1.6] #0.000003\n",
    "\n",
    "calgood = [0.89, 24.0, 5.1, 0.5, 1.5, 0.39, 0.002, 1.6, 0.36, 0.43, 0.0039, 0.92]#  ~2.6 errort\n",
    "\n",
    "\n",
    "\n",
    "#calgood =  [2.6, 39, 1, 14, 3.7, 1.2, 0.001, 0.37, 0.9, 0.7, 0.3, 1]\n",
    "\n",
    "\n",
    "Alluvium_Aua      = calgood[0]\n",
    "Alluvium_Fagaalu  = calgood[1]\n",
    "Alluvium_minor    = calgood[2]\n",
    "Alluvium_Utulei   = calgood[3]\n",
    "Alluvium_Vaipito  = calgood[4]\n",
    "Alluvium_Vatia    = calgood[5]\n",
    "Dikes             = calgood[6]\n",
    "Pago_inner_E      = calgood[7]\n",
    "Pago_inner_W      = calgood[8]\n",
    "Pago_outer        = calgood[9]\n",
    "Trachyte          = calgood[10]\n",
    "Alluvium_Laulii   = calgood[11]\n",
    "\n",
    "\n",
    "map_dic = {-12:Alluvium_Aua, \n",
    "           -14:Alluvium_Fagaalu, \n",
    "           -15:Alluvium_minor,\n",
    "           -13:Alluvium_Utulei,\n",
    "           -11:Alluvium_Vaipito,\n",
    "           -10:Alluvium_Vatia,\n",
    "           -50:Dikes,\n",
    "           -30:Pago_inner_E,\n",
    "           -40:Pago_inner_W,\n",
    "           -20:Pago_outer,\n",
    "           -60:Trachyte, \n",
    "           -16:Alluvium_Laulii}\n",
    "\n",
    "for i in map_dic:\n",
    "    HK_raster = np.where(HK_raster== i, map_dic[i], HK_raster)\n",
    "    \n",
    "HK_raster = np.where(HK_raster== 0, 7, HK_raster)   # this is for the areas not covered by HK zones, the number Should not actually maatter at all!\n",
    "\n",
    "#HK_raster = np.where(HK_raster== -90, 1, HK_raster) # this is for the areas that get messed up somehow\n",
    "#HK_raster = np.where(HK_raster== -70, 1, HK_raster) # this is for the areas that get messed up somehow\n",
    "\n",
    "if Plotnsave_plot: \n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "    qm = sr.plot_array(HK_raster, ax=ax)\n",
    "    ax.set_aspect(1); plt.colorbar(qm)\n",
    "\n",
    "'''Define the layers to be confined and define the horizontal and vertical \n",
    "hydraulic conductivity of the aquifer for the LPF package.'''\n",
    "\n",
    "# lpf data\n",
    "laytyp = 0\n",
    "vka = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'modelface'\n",
    "\n",
    "ml = flopy.modflow.Modflow(modelname, version='mf2005', exe_name=exe_name, model_ws=workspace, verbose=False)\n",
    "\n",
    "discret = flopy.modflow.ModflowDis(ml, nlay=nlay, nrow=nrow, ncol=ncol, laycbd=0,\n",
    "                                   delr=delr, delc=delc, top=top, botm=botm,\n",
    "                                   nper=nper, perlen=perlen, nstp=nstp)\n",
    "bas = flopy.modflow.ModflowBas(ml, ibound=ibound, strt=start_heads)\n",
    "lpf = flopy.modflow.ModflowLpf(ml, laytyp=laytyp, hk=HK_raster, vka=vka)\n",
    "#### ghb = flopy.modflow.ModflowGhb(ml, stress_period_data=ghb_data)\n",
    "rch = flopy.modflow.ModflowRch(ml, rech=rch_data)\n",
    "oc = flopy.modflow.ModflowOc(ml, stress_period_data=spd)\n",
    "pcg = flopy.modflow.ModflowPcg(ml, hclose=1.0e-6, rclose=3.0e-3, mxiter=100, iter1=50)\n",
    "drn = flopy.modflow.ModflowDrn(ml, ipakcb=53, print_flows=True, stress_period_data=stress_period_data_drain)  # ipakcb=53, is flag for writing SFR output to cell-by-cell budget (on unit 53)\n",
    "wel = flopy.modflow.ModflowWel(model = ml, stress_period_data=stress_period_data_PmpWells)\n",
    "\n",
    "# water level observations\n",
    "obs_data= []\n",
    "for i in range(0,nobs):\n",
    "    obs = flopy.modflow.HeadObservation(ml, obsname=obsnames[i], layer=layervals[i], row=rowvals[i], column=colvals[i], time_series_data=[[0,obsvals[i]]])\n",
    "    obs_data.append(obs)\n",
    "hob = flopy.modflow.ModflowHob(ml, iuhobsv = 7, hobdry=-999, obs_data = obs_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model \n",
    "\n",
    "if needed: #### Model checker\n",
    "https://notebook.community/brclark-usgs/flopy/examples/Notebooks/flopy3_ModelCheckerExample\n",
    "- ml.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.write_input()\n",
    "ml.run_model(silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot observations \n",
    "observations = np.loadtxt(os.path.join(workspace, '{}.hob.out'.format(modelname)), skiprows=1, usecols=[0,1])      # this block extracts observation data at each well field and determines what the maximum residual at any of the given points is\n",
    "comp_obs = np.ravel(np.split(observations, 2, 1)[0]) # the computed hed values at the obspts\n",
    "obs_obs = np.ravel(np.split(observations, 2, 1)[1]) # the observed hed values at the obspts\n",
    "\n",
    "# note positive residuals means model is calculating too high negative is model calculates too low \n",
    "residuals = []\n",
    "for idx, i in enumerate(observations):   \n",
    "    r = observations[idx][0]-observations[idx][1]\n",
    "    residuals.append(r)\n",
    "\n",
    "Howd_we_do = pd.DataFrame({\"Obs_hed_m\":obs_obs,\"Comp_hed_m\":comp_obs,\"Residual_m\":residuals})\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.title('Observed. vs Simulated.')\n",
    "plt.plot(Howd_we_do[\"Obs_hed_m\"], Howd_we_do[\"Comp_hed_m\"], '.')\n",
    "#plt.axis('equal')\n",
    "#plt.axis('square')\n",
    "plt.xlabel(\"Obs. head [m]\")\n",
    "plt.ylabel('Sim. head [m]')\n",
    "plt.ylim(0,90)\n",
    "plt.xlim(0,90)\n",
    "\n",
    "plt.plot([0,20,65],[0,20,65], color= \"grey\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(figurespace, \"calibration_result.pdf\"))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "me = np.mean(Howd_we_do.Residual_m)\n",
    "mea = np.mean(np.abs(Howd_we_do.Residual_m))\n",
    "rmse = np.sqrt(np.mean(Howd_we_do.Residual_m**2))\n",
    "print ('Mean Error: {:.2f}\\nMean Absolute Error: {:.2f}\\nRMS Error: {:.2f}'.format(me, mea, rmse))\n",
    "print(\"but remember, the model should be calibrated to a no well scenario, so dont worry about this\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esri_is_the_lamest_program_ever = \"SLR8ft_RCP45\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post process, map and extract results to heads raster file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop geometry to plot heads as colormap\n",
    "N = np.array([ncol, nrow, nlay])\n",
    "dx = np.array([delc, delr, abs(botm)])\n",
    "Lx = delc*ncol\n",
    "Ly = delr*nrow\n",
    "x = np.linspace(0. + dx[0] / 2., Lx - dx[0] / 2., N[0])\n",
    "y = np.linspace(0. + dx[1] / 2., Ly - dx[1] / 2., N[1])\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "\n",
    "# Extract heads data\n",
    "hds = bf.HeadFile(os.path.join(workspace, '{}.hds'.format(modelname)))\n",
    "times = hds.get_times() # simulation time, steady state\n",
    "head = hds.get_data(totim=times[-1])\n",
    "minv = 0\n",
    "maxv = head.max()\n",
    "\n",
    "# Plot em\n",
    "fig, axes = plt.subplots(1, 1, figsize=(10, 5))\n",
    "im1 = axes.pcolormesh(XX, YY, head[0], vmin=minv, vmax=maxv, cmap=plt.get_cmap('jet'))\n",
    "axes.set_title('(b) Lyr 1 Heads', loc='left')\n",
    "axes.set_xlabel('x (m)')\n",
    "axes.set_aspect('equal')\n",
    "axes.axis([XX.min(), XX.max(), YY.max(), YY.min()])\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "divider = make_axes_locatable(axes)\n",
    "cbar_ax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "fig.colorbar(im1, cax=cbar_ax)\n",
    "plt.show()\n",
    "\n",
    "# Write the heads layer(s) to a raster file\n",
    "# export head rasters \n",
    "output_raster = os.path.join(workspace, 'heads_{}.asc'.format(esri_is_the_lamest_program_ever))   # if there are multiple layers exports based on each layer\n",
    "grid = ml.modelgrid\n",
    "flopy.export.utils.export_array(grid, output_raster, head[0])\n",
    "\n",
    "# Project the output .asc into WGS84 space with manual  ASC header modification \n",
    "new_first = ('ncols {}\\n'                        # these are the parameters for the .asc file\n",
    "             'nrows {}\\n'\n",
    "             'xllcorner {}\\n'\n",
    "             'yllcorner {}\\n'\n",
    "             'cellsize {}\\n'\n",
    "             'NODATA_value -999.0'.format(ncol,nrow, xll, yll, np.mean([delc, delr]) ))\n",
    "\n",
    "with open(os.path.join('.', output_raster), 'r') as fin:   # open file \n",
    "    data = fin.read().splitlines(True)\n",
    "with open(os.path.join('.', output_raster), 'w') as fout:     # delete first line\n",
    "    fout.writelines(data[6:])\n",
    "    \n",
    "with open(os.path.join('.', output_raster), 'r+') as file:                # add in new first line and save file  \n",
    "    file_data = file.read()\n",
    "    file. seek(0, 0)\n",
    "    file. write(new_first + '\\n' + file_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Depth to water\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super basic depth to water calculation, Currently allows for negative depths (i.e. flooding)\n",
    "Heads_raw = np.loadtxt(os.path.join(workspace, 'heads_{}.asc'.format(esri_is_the_lamest_program_ever)), skiprows=6)   # the 7th row was a no data row for some reason not sure why, if another DEM is used might need to skiprows back to 6\n",
    "Dep_to_wat = top-Heads_raw\n",
    "\n",
    "# Write the GIS asc raster from the NP array \n",
    "output_raster = os.path.join(workspace, 'dep2Wat_{}.asc'.format(esri_is_the_lamest_program_ever))   # if there are multiple layers exports based on each layer\n",
    "grid = ml.modelgrid\n",
    "flopy.export.utils.export_array(grid, output_raster, Dep_to_wat)\n",
    "\n",
    "# Project the output .asc into WGS84 space with manual  ASC header modification \n",
    "new_first = ('ncols {}\\n'                        # these are the parameters for the .asc file\n",
    "             'nrows {}\\n'\n",
    "             'xllcorner {}\\n'\n",
    "             'yllcorner {}\\n'\n",
    "             'cellsize {}\\n'\n",
    "             'NODATA_value -999.0'.format(ncol,nrow, xll, yll, np.mean([delc, delr]) ))\n",
    "\n",
    "with open(os.path.join('.', output_raster), 'r') as fin:   # open file \n",
    "    data = fin.read().splitlines(True)\n",
    "with open(os.path.join('.', output_raster), 'w') as fout:     # delete first line\n",
    "    fout.writelines(data[6:])\n",
    "    \n",
    "with open(os.path.join('.', output_raster), 'r+') as file:                # add in new first line and save file  \n",
    "    file_data = file.read()\n",
    "    file. seek(0, 0)\n",
    "    file. write(new_first + '\\n' + file_data)\n",
    "    \n",
    "    \n",
    "if Plotnsave_plot: \n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "    qm = sr.plot_array(Dep_to_wat, ax=ax)\n",
    "    ax.set_aspect(1); plt.colorbar(qm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
